{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Workshop Week 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning for Name Gender Classification\n",
    "\n",
    "We have already seen the following code for partitioning the data of name gender classification and feature extraction. The code is changed slightly so that the labels are numerical (0 for male, 1 for female). This is the format required for Keras:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package names to\n",
      "[nltk_data]     C:\\Users\\liamf\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package names is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('names')\n",
    "from nltk.corpus import names\n",
    "m = names.words('male.txt')\n",
    "f = names.words('female.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.seed(1234) # Set the random seed to allow replicability\n",
    "names = ([(name,0) for name in m] +\n",
    "         [(name,1) for name in f])\n",
    "random.shuffle(names)\n",
    "train_names = names[1000:]\n",
    "devtest_names = names[500:1000]\n",
    "test_names = names[:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_character(c):\n",
    "    alphabet = 'abcdefghijklmnopqrstuvwxyz'\n",
    "    result = [0]*(len(alphabet)+1)\n",
    "    i = alphabet.find(c.lower())\n",
    "    if i >= 0:\n",
    "        result[i] = 1\n",
    "    else:\n",
    "        result[len(alphabet)] = 1 # character is out of the alphabet\n",
    "    return result\n",
    "\n",
    "def gender_features_n(word, n=2):\n",
    "    \"Return the one-hot encodings of the last n characters\"\n",
    "    features = []\n",
    "    for i in range(n):\n",
    "        if i < len(word):\n",
    "            features = one_hot_character(word[-i-1]) + features\n",
    "        else:\n",
    "            features = one_hot_character(' ') + features\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gender_features_n(\"Mary\", n=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "54"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's determine the number of features so that we can use this information when we design the neural network\n",
    "len(gender_features_n(\"Mary\", n=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise: Simple Neural Network\n",
    "Design a simple neural network that has 54 input cells (that's the number of gender features for $n=2$, as we have seen above), and one output cell (without a hidden layer). The output cell will be used to classify the name between male (output=0) and female (output=1). This is therefore an instance of **binary classification**. Pay attention to the right activation function! This simple model, without hidden layers, is equivalent to a **logistic regression** classifier. The model summary should look like this:\n",
    "\n",
    "```\n",
    "Layer (type)                 Output Shape              Param #   \n",
    "=================================================================\n",
    "dense_2 (Dense)              (None, 1)                 55        \n",
    "=================================================================\n",
    "Total params: 55\n",
    "Trainable params: 55\n",
    "Non-trainable params: 0\n",
    "```\n",
    "\n",
    "\n",
    "Compile the model and provide the right loss function. Use `'rmsprop'` as the optimiser, and include `'accuracy'` as an evaluation metric. \n",
    "Run the network **for 100 epochs** using batch size of 100, and observe the results. \n",
    "\n",
    "Answer the following questions:\n",
    "\n",
    "1. What is the best result on the validation set?\n",
    "2. At the epoch with best result on the validation set, what is the result on the training set?\n",
    "3. Is the system overfitting? Justify your answer.\n",
    "4. Do we really need 100 epochs? Do we need more than 100 epochs? would the system run better with less epochs?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.config.experimental.list_physical_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\liamf\\anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py:1768: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n",
      "  warnings.warn('An interactive session is already active. This can '\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.compat.v1 import ConfigProto\n",
    "from tensorflow.compat.v1 import InteractiveSession\n",
    "\n",
    "config = ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = InteractiveSession(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# Write your model here\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(1, activation='relu', input_shape=(54,)))\n",
    "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "train_data = np.array([gender_features_n(name, n=2) for name, label in train_names])\n",
    "train_labels = np.array([label for name, label in train_names])\n",
    "\n",
    "devtest_data = np.array([gender_features_n(name, n=2) for name, label in devtest_names])\n",
    "devtest_labels = np.array([label for name, label in devtest_names])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_12 (Dense)            (None, 1)                 55        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 55\n",
      "Trainable params: 55\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(write additional code for the partition of the data, your experiments, and your analysis. Write the answers to the questions.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.6755 - acc: 0.6418 - val_loss: 0.7794 - val_acc: 0.6040\n",
      "Epoch 2/100\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.6460 - acc: 0.6444 - val_loss: 0.7083 - val_acc: 0.6040\n",
      "Epoch 3/100\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.5947 - acc: 0.6452 - val_loss: 0.6390 - val_acc: 0.6080\n",
      "Epoch 4/100\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.5801 - acc: 0.6465 - val_loss: 0.6181 - val_acc: 0.6200\n",
      "Epoch 5/100\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.5648 - acc: 0.6584 - val_loss: 0.6018 - val_acc: 0.6180\n",
      "Epoch 6/100\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.5532 - acc: 0.7019 - val_loss: 0.5904 - val_acc: 0.7040\n",
      "Epoch 7/100\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.5434 - acc: 0.7310 - val_loss: 0.5787 - val_acc: 0.7040\n",
      "Epoch 8/100\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.5346 - acc: 0.7314 - val_loss: 0.5674 - val_acc: 0.7020\n",
      "Epoch 9/100\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.5251 - acc: 0.7349 - val_loss: 0.5575 - val_acc: 0.7140\n",
      "Epoch 10/100\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.5167 - acc: 0.7481 - val_loss: 0.5491 - val_acc: 0.7140\n",
      "Epoch 11/100\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.5094 - acc: 0.7486 - val_loss: 0.5421 - val_acc: 0.7140\n",
      "Epoch 12/100\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.5044 - acc: 0.7488 - val_loss: 0.5363 - val_acc: 0.7140\n",
      "Epoch 13/100\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.4986 - acc: 0.7491 - val_loss: 0.5318 - val_acc: 0.7200\n",
      "Epoch 14/100\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.4935 - acc: 0.7504 - val_loss: 0.5285 - val_acc: 0.7220\n",
      "Epoch 15/100\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.4891 - acc: 0.7537 - val_loss: 0.5284 - val_acc: 0.7260\n",
      "Epoch 16/100\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 0.4855 - acc: 0.7558 - val_loss: 0.5431 - val_acc: 0.7240\n",
      "Epoch 17/100\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.4822 - acc: 0.7510 - val_loss: 0.5405 - val_acc: 0.7320\n",
      "Epoch 18/100\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 0.4787 - acc: 0.7529 - val_loss: 0.5388 - val_acc: 0.7220\n",
      "Epoch 19/100\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.4757 - acc: 0.7539 - val_loss: 0.5367 - val_acc: 0.7280\n",
      "Epoch 20/100\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 0.4749 - acc: 0.7569 - val_loss: 0.5347 - val_acc: 0.7360\n",
      "Epoch 21/100\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.4729 - acc: 0.7611 - val_loss: 0.5331 - val_acc: 0.7420\n",
      "Epoch 22/100\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 0.4710 - acc: 0.7668 - val_loss: 0.5320 - val_acc: 0.7440\n",
      "Epoch 23/100\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.4695 - acc: 0.7704 - val_loss: 0.5316 - val_acc: 0.7400\n",
      "Epoch 24/100\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.4682 - acc: 0.7679 - val_loss: 0.5315 - val_acc: 0.7440\n",
      "Epoch 25/100\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.4669 - acc: 0.7690 - val_loss: 0.5315 - val_acc: 0.7440\n",
      "Epoch 26/100\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.4659 - acc: 0.7697 - val_loss: 0.5319 - val_acc: 0.7440\n",
      "Epoch 27/100\n",
      "14/14 [==============================] - 0s 20ms/step - loss: 0.4652 - acc: 0.7729 - val_loss: 0.5334 - val_acc: 0.7500\n",
      "Epoch 28/100\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 0.4644 - acc: 0.7704 - val_loss: 0.5520 - val_acc: 0.7520\n",
      "Epoch 29/100\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.4637 - acc: 0.7746 - val_loss: 0.5522 - val_acc: 0.7520\n",
      "Epoch 30/100\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.4632 - acc: 0.7726 - val_loss: 0.5517 - val_acc: 0.7560\n",
      "Epoch 31/100\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.4627 - acc: 0.7765 - val_loss: 0.5518 - val_acc: 0.7560\n",
      "Epoch 32/100\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.4622 - acc: 0.7778 - val_loss: 0.5510 - val_acc: 0.7600\n",
      "Epoch 33/100\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.4618 - acc: 0.7782 - val_loss: 0.5508 - val_acc: 0.7640\n",
      "Epoch 34/100\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.4615 - acc: 0.7821 - val_loss: 0.5507 - val_acc: 0.7660\n",
      "Epoch 35/100\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.4613 - acc: 0.7833 - val_loss: 0.5504 - val_acc: 0.7620\n",
      "Epoch 36/100\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.4611 - acc: 0.7778 - val_loss: 0.5503 - val_acc: 0.7660\n",
      "Epoch 37/100\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.4608 - acc: 0.7808 - val_loss: 0.5501 - val_acc: 0.7660\n",
      "Epoch 38/100\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.4605 - acc: 0.7823 - val_loss: 0.5505 - val_acc: 0.7620\n",
      "Epoch 39/100\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.4604 - acc: 0.7782 - val_loss: 0.5507 - val_acc: 0.7640\n",
      "Epoch 40/100\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.4602 - acc: 0.7782 - val_loss: 0.5497 - val_acc: 0.7620\n",
      "Epoch 41/100\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 0.4600 - acc: 0.7798 - val_loss: 0.5497 - val_acc: 0.7640\n",
      "Epoch 42/100\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 0.4600 - acc: 0.7802 - val_loss: 0.5505 - val_acc: 0.7620\n",
      "Epoch 43/100\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.4599 - acc: 0.7805 - val_loss: 0.5503 - val_acc: 0.7640\n",
      "Epoch 44/100\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 0.4597 - acc: 0.7820 - val_loss: 0.5505 - val_acc: 0.7600\n",
      "Epoch 45/100\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 0.4597 - acc: 0.7814 - val_loss: 0.5505 - val_acc: 0.7660\n",
      "Epoch 46/100\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.4596 - acc: 0.7814 - val_loss: 0.5504 - val_acc: 0.7660\n",
      "Epoch 47/100\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.4595 - acc: 0.7824 - val_loss: 0.5501 - val_acc: 0.7640\n",
      "Epoch 48/100\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 0.4596 - acc: 0.7814 - val_loss: 0.5503 - val_acc: 0.7640\n",
      "Epoch 49/100\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.4594 - acc: 0.7833 - val_loss: 0.5502 - val_acc: 0.7640\n",
      "Epoch 50/100\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 0.4594 - acc: 0.7825 - val_loss: 0.5503 - val_acc: 0.7640\n",
      "Epoch 51/100\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.4594 - acc: 0.7824 - val_loss: 0.5499 - val_acc: 0.7660\n",
      "Epoch 52/100\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.4592 - acc: 0.7831 - val_loss: 0.5499 - val_acc: 0.7660\n",
      "Epoch 53/100\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 0.4592 - acc: 0.7841 - val_loss: 0.5500 - val_acc: 0.7660\n",
      "Epoch 54/100\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.4592 - acc: 0.7831 - val_loss: 0.5501 - val_acc: 0.7680\n",
      "Epoch 55/100\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.4592 - acc: 0.7815 - val_loss: 0.5497 - val_acc: 0.7680\n",
      "Epoch 56/100\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.4591 - acc: 0.7843 - val_loss: 0.5500 - val_acc: 0.7700\n",
      "Epoch 57/100\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 0.4591 - acc: 0.7820 - val_loss: 0.5501 - val_acc: 0.7680\n",
      "Epoch 58/100\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.4591 - acc: 0.7827 - val_loss: 0.5502 - val_acc: 0.7680\n",
      "Epoch 59/100\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.4591 - acc: 0.7837 - val_loss: 0.5502 - val_acc: 0.7700\n",
      "Epoch 60/100\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.4590 - acc: 0.7846 - val_loss: 0.5502 - val_acc: 0.7700\n",
      "Epoch 61/100\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.4590 - acc: 0.7834 - val_loss: 0.5498 - val_acc: 0.7680\n",
      "Epoch 62/100\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.4590 - acc: 0.7846 - val_loss: 0.5496 - val_acc: 0.7680\n",
      "Epoch 63/100\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.4590 - acc: 0.7838 - val_loss: 0.5498 - val_acc: 0.7680\n",
      "Epoch 64/100\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.4590 - acc: 0.7840 - val_loss: 0.5501 - val_acc: 0.7700\n",
      "Epoch 65/100\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.4589 - acc: 0.7838 - val_loss: 0.5501 - val_acc: 0.7700\n",
      "Epoch 66/100\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.4589 - acc: 0.7843 - val_loss: 0.5497 - val_acc: 0.7700\n",
      "Epoch 67/100\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 0.4590 - acc: 0.7841 - val_loss: 0.5504 - val_acc: 0.7700\n",
      "Epoch 68/100\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.4589 - acc: 0.7834 - val_loss: 0.5503 - val_acc: 0.7700\n",
      "Epoch 69/100\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 0.4589 - acc: 0.7846 - val_loss: 0.5502 - val_acc: 0.7680\n",
      "Epoch 70/100\n",
      "14/14 [==============================] - 0s 16ms/step - loss: 0.4589 - acc: 0.7828 - val_loss: 0.5502 - val_acc: 0.7700\n",
      "Epoch 71/100\n",
      "14/14 [==============================] - 0s 12ms/step - loss: 0.4589 - acc: 0.7841 - val_loss: 0.5498 - val_acc: 0.7680\n",
      "Epoch 72/100\n",
      "14/14 [==============================] - 0s 12ms/step - loss: 0.4589 - acc: 0.7844 - val_loss: 0.5495 - val_acc: 0.7680\n",
      "Epoch 73/100\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 0.4588 - acc: 0.7847 - val_loss: 0.5492 - val_acc: 0.7680\n",
      "Epoch 74/100\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.4589 - acc: 0.7843 - val_loss: 0.5499 - val_acc: 0.7700\n",
      "Epoch 75/100\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.4589 - acc: 0.7844 - val_loss: 0.5500 - val_acc: 0.7680\n",
      "Epoch 76/100\n",
      "14/14 [==============================] - 0s 12ms/step - loss: 0.4588 - acc: 0.7843 - val_loss: 0.5506 - val_acc: 0.7700\n",
      "Epoch 77/100\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.4588 - acc: 0.7844 - val_loss: 0.5502 - val_acc: 0.7700\n",
      "Epoch 78/100\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.4589 - acc: 0.7849 - val_loss: 0.5498 - val_acc: 0.7700\n",
      "Epoch 79/100\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.4588 - acc: 0.7849 - val_loss: 0.5500 - val_acc: 0.7700\n",
      "Epoch 80/100\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.4588 - acc: 0.7849 - val_loss: 0.5497 - val_acc: 0.7700\n",
      "Epoch 81/100\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 0.4588 - acc: 0.7854 - val_loss: 0.5498 - val_acc: 0.7700\n",
      "Epoch 82/100\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.4588 - acc: 0.7853 - val_loss: 0.5499 - val_acc: 0.7700\n",
      "Epoch 83/100\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.4587 - acc: 0.7851 - val_loss: 0.5499 - val_acc: 0.7700\n",
      "Epoch 84/100\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.4588 - acc: 0.7831 - val_loss: 0.5496 - val_acc: 0.7700\n",
      "Epoch 85/100\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 0.4588 - acc: 0.7846 - val_loss: 0.5492 - val_acc: 0.7700\n",
      "Epoch 86/100\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.4587 - acc: 0.7856 - val_loss: 0.5491 - val_acc: 0.7700\n",
      "Epoch 87/100\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.4587 - acc: 0.7846 - val_loss: 0.5493 - val_acc: 0.7700\n",
      "Epoch 88/100\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.4588 - acc: 0.7853 - val_loss: 0.5491 - val_acc: 0.7680\n",
      "Epoch 89/100\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 0.4588 - acc: 0.7850 - val_loss: 0.5496 - val_acc: 0.7700\n",
      "Epoch 90/100\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.4588 - acc: 0.7850 - val_loss: 0.5500 - val_acc: 0.7700\n",
      "Epoch 91/100\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.4588 - acc: 0.7847 - val_loss: 0.5494 - val_acc: 0.7700\n",
      "Epoch 92/100\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.4588 - acc: 0.7853 - val_loss: 0.5498 - val_acc: 0.7700\n",
      "Epoch 93/100\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.4586 - acc: 0.7854 - val_loss: 0.5501 - val_acc: 0.7700\n",
      "Epoch 94/100\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.4588 - acc: 0.7847 - val_loss: 0.5501 - val_acc: 0.7700\n",
      "Epoch 95/100\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.4587 - acc: 0.7853 - val_loss: 0.5496 - val_acc: 0.7680\n",
      "Epoch 96/100\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.4587 - acc: 0.7844 - val_loss: 0.5495 - val_acc: 0.7660\n",
      "Epoch 97/100\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.4587 - acc: 0.7847 - val_loss: 0.5498 - val_acc: 0.7680\n",
      "Epoch 98/100\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.4587 - acc: 0.7836 - val_loss: 0.5491 - val_acc: 0.7660\n",
      "Epoch 99/100\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.4588 - acc: 0.7843 - val_loss: 0.5491 - val_acc: 0.7660\n",
      "Epoch 100/100\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.4587 - acc: 0.7840 - val_loss: 0.5495 - val_acc: 0.7680\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_data,\n",
    "                    train_labels,\n",
    "                    epochs=100,\n",
    "                    batch_size=512,\n",
    "                    validation_data=(devtest_data, devtest_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(1, len(loss) + 1)\n",
    "\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'val_acc' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-33-c2a53e63a5c2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mamax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval_acc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'val_acc' is not defined"
     ]
    }
   ],
   "source": [
    "np.amax(val_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise: A Deeper Network\n",
    "Experiment with a network that has one hidden dense layer with a `'relu'` activation. The resulting system is no longer a logistic regression classifier, it's something more complex. Try the following sizes in the hidden layer:\n",
    "\n",
    "* 5, 7, 10\n",
    "\n",
    "Answer the following questions:\n",
    "\n",
    "1. Which system performed best on the dev-test set?\n",
    "2. Would you add more or less cells in the hidden layer? Justify your answer.\n",
    "3. Is this system better than the simpler system of the previous exercise? Justify your answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# Write your model here\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(5, activation='relu', input_shape=(54,)))\n",
    "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optional: Deep Learning with the Movie Review Corpus\n",
    "The notebook [W04L1-2-MovieReviews.ipynb](../lectures/W04L1-2-MovieReviews.ipynb) has several questions at the end, repeated below. Try to answer these, and indeed try other variants!\n",
    "\n",
    "* We were using 2 hidden layers. Try to use 1 or 3 hidden layers and see how it affects validation and test accuracy.\n",
    "* Try to use layers with more hidden units or less hidden units: 32 units, 64 units...\n",
    "* Try to use the `mse` loss function instead of `binary_crossentropy`.\n",
    "* Try to use the `tanh` activation (an activation that was popular in the early days of neural networks) instead of `relu`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
